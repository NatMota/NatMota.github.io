{"componentChunkName":"component---src-templates-blog-template-js","path":"/blogs/trying-out-compact-llms-for-product-work/","result":{"data":{"blog":{"content":{"raw":"{\"nodeType\":\"document\",\"data\":{},\"content\":[{\"nodeType\":\"heading-4\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Motivation\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"I wanted to recreate a personal assistant environment for product managers who:\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Do not have access to, or are not allowed to place sensitive data on online services\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Want to use software for free\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Know python but have no time to learn related tools \",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"May be concerned with software licensing restrictions\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Are curious about LLM's and are exposed to them already\",\"marks\":[],\"data\":{}}]}]}]},{\"nodeType\":\"heading-4\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Mise en place\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"I'm using an apple silicon mac. Use ChatGPT or Claude to guide you through system specific setup.\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Computer with about 1.5GB of disk space, about 2GB of free ram, CUDA gpu a plus\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Used a Mac air M1 fine. \",\"marks\":[],\"data\":{}}]}]}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Python IDE of your choice\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Create a new python environment:\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"python -m venv llm_env\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"source llm_env/bin/activate \",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"python -m pip install --upgrade pip\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"pip install transformers torch\",\"marks\":[],\"data\":{}}]}]}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Essential facts and lexicon\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Large language models (LLM's) are systems specialised in handling \",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"language\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" by\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"1. Being painstakingly conditioned to generate 'correct' \",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"language\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" patterns\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"2. Taking a \",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"language\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\" input and converting it into mathematical symbols\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"3. Select the next best mathematical symbols based on previous conditioning and convert the result into \",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"language \",\"marks\":[{\"type\":\"bold\"}],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"output\",\"marks\":[],\"data\":{}}]}]}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"ChatGPT is an LLM that has an additional layer of conditioning to specifically work better in back and forth conversations\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Language input into an LLM is a prompt\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"LLM's are conditioned answer a question 'correctly' by matching the core concepts of the prompt to trained language structures\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"This means that much like a conversation, the output will never be exactly the same across two equal prompts\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Software code is much more structured than human language, so LLM's will introduce less variety when looking for the right solution, but variety is still possible\",\"marks\":[],\"data\":{}}]}]}]}]}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Prompts are converted into tokens. As a simple example, every word in a prompt will be matched to a token. Imagine tokens as numbers that correspond to a specific word. \",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"LLM's can be made more effective by:\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"improving the amount and quality of language data available to condition them \",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"improving their ability to detect language structures and hierarchy\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"improving their ability to process more information in each conversation or prompt\",\"marks\":[],\"data\":{}}]}]}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"One simple way to compare how much information LLM's can meaningfully process in a conversation or a prompt response is to compare their context window\",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"A context window is the limit in the chain of tokens that an LLM can hold at once when replying in a conversation or prompt, including the conversation history \",\"marks\":[],\"data\":{}},{\"nodeType\":\"text\",\"value\":\"AND response\",\"marks\":[{\"type\":\"bold\"}],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"For example, Chat GPT's free version has a context window of 8k tokens, but the enterprise version is 128k tokens -  This means it can operate between: \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"12-13 pages of single-spaced text in the free version if you imagined it as one doc\",\"marks\":[],\"data\":{}}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"197 pages doc on the enterprise version\",\"marks\":[],\"data\":{}}]}]}]}]}]}]},{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"Commercial conversational LLM's are extensively refined and factually enriched i.e. with true historical events and mathematical reasoning... but this requires a lot of manual work and gives you an inflated impression of their raw ability! \",\"marks\":[],\"data\":{}}]},{\"nodeType\":\"unordered-list\",\"data\":{},\"content\":[{\"nodeType\":\"list-item\",\"data\":{},\"content\":[{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"For this alone it is very educational to play with non-tuned LLM's\",\"marks\":[],\"data\":{}}]}]}]}]}]}]}]},{\"nodeType\":\"paragraph\",\"data\":{},\"content\":[{\"nodeType\":\"text\",\"value\":\"\",\"marks\":[],\"data\":{}}]}]}","references":[]},"title":"Trying out compact LLMs for product work","image":{"gatsbyImageData":{"images":{"sources":[{"srcSet":"https://images.ctfassets.net/bgaxkx6xut76/oAWyY6WnETUF66EGlynpk/18f60666fc726b55335e3729ffd7b74d/Screenshot_2024-08-11_at_21.13.30.png?w=317&h=77&q=50&fm=webp 317w,\nhttps://images.ctfassets.net/bgaxkx6xut76/oAWyY6WnETUF66EGlynpk/18f60666fc726b55335e3729ffd7b74d/Screenshot_2024-08-11_at_21.13.30.png?w=634&h=153&q=50&fm=webp 634w,\nhttps://images.ctfassets.net/bgaxkx6xut76/oAWyY6WnETUF66EGlynpk/18f60666fc726b55335e3729ffd7b74d/Screenshot_2024-08-11_at_21.13.30.png?w=1268&h=306&q=50&fm=webp 1268w","sizes":"(min-width: 1268px) 1268px, 100vw","type":"image/webp"}],"fallback":{"src":"https://images.ctfassets.net/bgaxkx6xut76/oAWyY6WnETUF66EGlynpk/18f60666fc726b55335e3729ffd7b74d/Screenshot_2024-08-11_at_21.13.30.png?w=1268&h=306&q=50&fm=png","srcSet":"https://images.ctfassets.net/bgaxkx6xut76/oAWyY6WnETUF66EGlynpk/18f60666fc726b55335e3729ffd7b74d/Screenshot_2024-08-11_at_21.13.30.png?w=317&h=77&q=50&fm=png 317w,\nhttps://images.ctfassets.net/bgaxkx6xut76/oAWyY6WnETUF66EGlynpk/18f60666fc726b55335e3729ffd7b74d/Screenshot_2024-08-11_at_21.13.30.png?w=634&h=153&q=50&fm=png 634w,\nhttps://images.ctfassets.net/bgaxkx6xut76/oAWyY6WnETUF66EGlynpk/18f60666fc726b55335e3729ffd7b74d/Screenshot_2024-08-11_at_21.13.30.png?w=1268&h=306&q=50&fm=png 1268w","sizes":"(min-width: 1268px) 1268px, 100vw"}},"layout":"constrained","backgroundColor":"#181818","width":1268,"height":306}}},"contentfulBlogPostDescriptionTextNode":{"description":"I tried to find a safe way to run an LLM on your personal computer without licensing or data transfer worries. "}},"pageContext":{"slug":"trying-out-compact-llms-for-product-work"}},"staticQueryHashes":["3303551625"],"slicesMap":{}}